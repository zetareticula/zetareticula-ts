apiVersion: apps/v1
kind: Deployment
metadata:
  name: moe-inference-system
  namespace: production
  labels:
    app: moe-inference-system
    tier: backend
    environment: production
spec:
  replicas: 3
  selector:
    matchLabels:
      app: moe-inference-system
      tier: backend
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
    type: RollingUpdate
  template:
    metadata:
      labels:
        app: moe-inference-system
        tier: backend
        environment: production
    spec:
      containers:
      - name: moe-inference-system
        image: ${DOCKER_REGISTRY}moe-inference-system:${VERSION:-latest}
        imagePullPolicy: Always
        ports:
        - containerPort: 3000
          name: http
        envFrom:
        - configMapRef:
            name: moe-inference-system-config
        - secretRef:
            name: moe-inference-system-secrets
        resources:
          requests:
            cpu: "100m"
            memory: "256Mi"
          limits:
            cpu: "1000m"
            memory: "1Gi"
        livenessProbe:
          httpGet:
            path: /health
            port: http
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: http
          initialDelaySeconds: 5
          periodSeconds: 5
      restartPolicy: Always
